# ğŸ©º MediBot â€” A Medical Chatbot Powered by LLMs

**MediBot** is an AI-powered medical assistant chatbot designed to answer questions based on trusted medical literature â€” the same books doctors study and refer to. This project was inspired by my internship at **Hackensack Meridian Health**, where we worked on a clinical summarization chatbot using large language models.

> âš ï¸ This is a **research and educational prototype** and **not intended for clinical or diagnostic use.**

---

## ğŸ’¡ Key Features

- ğŸ“š **Medical Knowledge Base**  
  Load and index standard medical textbooks and PDFs into a vector store using embeddings.

- ğŸ” **Context-Aware Question Answering**  
  Uses retrieval-augmented generation (RAG) to answer questions using relevant medical context.

- ğŸ¤– **LLM-Powered Chat Interface**  
  Built using cutting-edge models from HuggingFace and accelerated with Groq for faster inference.

- ğŸŒ **Interactive Frontend**  
  User-friendly web interface built with Streamlit for smooth interaction.

---

## ğŸ›  Tech Stack

| Tool          | Purpose |
|---------------|---------|
| ğŸ”— [LangChain](https://www.langchain.com/) | Building the RAG pipeline |
| ğŸ¤— [HuggingFace Transformers](https://huggingface.co/) | Access to open-source LLMs |
| âš¡ [Groq](https://groq.com/) | Fast inference for LLM responses |
| ğŸ§  [FAISS](https://github.com/facebookresearch/faiss) | Vector similarity search |
| ğŸ“Š [Streamlit](https://streamlit.io/) | Web frontend |
| ğŸ Python | Core logic and orchestration |

---

## ğŸ“¸ Screenshots

Hereâ€™s a quick look at the MediBot interface:  
![MediBot Screenshot](assets/screenshot.png)

---

## ğŸ§­ System Architecture

The high-level architecture of MediBot looks like this:  
![MediBot Architecture](assets/architecture.png)


## ğŸš€ How It Works

1. **Load PDFs** â€” Chunk medical PDFs and convert them into text.  
2. **Create Embeddings** â€” Use HuggingFace models to generate vector embeddings.  
3. **Store in Vector DB** â€” Store chunks in FAISS for fast retrieval.  
4. **Ask a Question** â€” User enters a question in the UI.  
5. **RAG Pipeline** â€” LangChain retrieves relevant chunks and feeds them to the LLM.  
6. **LLM Response** â€” The LLM generates a contextual answer shown to the user.  

---
